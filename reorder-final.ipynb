{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12985799,"sourceType":"datasetVersion","datasetId":8219345}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pymupdf easyocr pillow numpy torch\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T11:32:00.181727Z","iopub.execute_input":"2025-09-07T11:32:00.182415Z","iopub.status.idle":"2025-09-07T11:33:33.110337Z","shell.execute_reply.started":"2025-09-07T11:32:00.182389Z","shell.execute_reply":"2025-09-07T11:33:33.109747Z"},"_kg_hide-output":true},"outputs":[{"name":"stdout","text":"Collecting pymupdf\n  Downloading pymupdf-1.26.4-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\nRequirement already satisfied: easyocr in /usr/local/lib/python3.11/dist-packages (1.7.2)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.11/dist-packages (from easyocr) (0.21.0+cu124)\nRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from easyocr) (4.11.0.86)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from easyocr) (1.15.3)\nRequirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from easyocr) (0.25.2)\nRequirement already satisfied: python-bidi in /usr/local/lib/python3.11/dist-packages (from easyocr) (0.6.6)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from easyocr) (6.0.2)\nRequirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.1.1)\nRequirement already satisfied: pyclipper in /usr/local/lib/python3.11/dist-packages (from easyocr) (1.3.0.post6)\nRequirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from easyocr) (1.11.1.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (2.37.0)\nRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (2025.6.11)\nRequirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (25.0)\nRequirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (0.4)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\nDownloading pymupdf-1.26.4-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pymupdf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pymupdf-1.26.4\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import fitz\nimport easyocr\nimport tempfile\nimport os\nimport re\nimport json\nimport logging\nfrom pathlib import Path\nfrom PIL import Image, ImageEnhance\nfrom collections import defaultdict, Counter\nimport numpy as np\nimport threading\nfrom concurrent.futures import ThreadPoolExecutor\nimport torch\n\n# For file upload widget\ntry:\n    from ipywidgets import widgets, interact, interactive, fixed, interact_manual\n    from IPython.display import display, HTML, clear_output\n    import ipywidgets as widgets\n    WIDGETS_AVAILABLE = True\nexcept ImportError:\n    WIDGETS_AVAILABLE = False\n    print(\"ipywidgets not available. Install with: pip install ipywidgets\")\n\nclass AdaptivePDFReorderer:\n    def __init__(self, gpu_optimization=True, max_workers=None):\n        self.setup_logging()\n        self.gpu_optimization = gpu_optimization\n        self.max_workers = max_workers or min(8, os.cpu_count())\n        self.uploaded_files = {}\n        \n        # Initialize EasyOCR with GPU optimization\n        self.reader = self._initialize_ocr()\n        \n        # Analysis results\n        self.page_findings = {}\n        self.confidence_scores = {}\n        self.disambiguation_data = {}\n        \n        self.logger.info(f\"Initialized with GPU optimization: {gpu_optimization}\")\n        self.logger.info(f\"Max workers: {self.max_workers}\")\n    \n    def setup_logging(self):\n        logging.basicConfig(\n            level=logging.INFO,\n            format='%(asctime)s - %(levelname)s - %(message)s'\n        )\n        self.logger = logging.getLogger(__name__)\n    \n    def create_upload_widget(self):\n        \"\"\"Create file upload widget for notebooks\"\"\"\n        if not WIDGETS_AVAILABLE:\n            print(\"Widget upload not available. Please install ipywidgets:\")\n            print(\"pip install ipywidgets\")\n            print(\"jupyter nbextension enable --py widgetsnbextension\")\n            return None\n        \n        # File upload widget\n        upload_widget = widgets.FileUpload(\n            accept='.pdf',\n            multiple=True,\n            description='Upload PDF(s)',\n            style={'button_color': '#667eea'}\n        )\n        \n        # Output widget for results\n        output_widget = widgets.Output()\n        \n        # Process button\n        process_button = widgets.Button(\n            description='🔄 Process PDFs',\n            disabled=True,\n            button_style='primary',\n            layout=widgets.Layout(width='200px', height='40px')\n        )\n        \n        # Progress bar\n        progress_bar = widgets.IntProgress(\n            value=0,\n            min=0,\n            max=100,\n            description='Progress:',\n            bar_style='info',\n            style={'bar_color': '#667eea'},\n            layout=widgets.Layout(width='400px')\n        )\n        \n        # Status text\n        status_text = widgets.HTML(\n            value=\"<p style='color: #666;'>Please upload PDF files to begin</p>\"\n        )\n        \n        def on_upload_change(change):\n            \"\"\"Handle file upload\"\"\"\n            with output_widget:\n                clear_output()\n                \n                if upload_widget.value:\n                    self.uploaded_files = {}\n                    file_info = []\n                    \n                    for uploaded_file in upload_widget.value:\n                        filename = uploaded_file.name\n                        file_content = uploaded_file.content\n                        \n                        # Save uploaded file temporarily\n                        temp_path = f\"/tmp/{filename}\"\n                        with open(temp_path, 'wb') as f:\n                            f.write(file_content)\n                        \n                        self.uploaded_files[filename] = temp_path\n                        \n                        # Get file size\n                        file_size = len(file_content)\n                        size_mb = file_size / (1024 * 1024)\n                        \n                        file_info.append(f\"📄 {filename} ({size_mb:.1f} MB)\")\n                    \n                    # Update status\n                    status_text.value = f\"\"\"\n                    <div style='background: #e8f5e8; padding: 15px; border-radius: 8px; border-left: 4px solid #4caf50;'>\n                        <h4 style='color: #2e7d32; margin: 0 0 10px 0;'>✅ Files Uploaded Successfully</h4>\n                        {'<br>'.join(file_info)}\n                        <p style='margin: 10px 0 0 0; color: #555;'>Click \"Process PDFs\" to start reordering</p>\n                    </div>\n                    \"\"\"\n                    \n                    process_button.disabled = False\n                    print(f\"Uploaded {len(self.uploaded_files)} PDF file(s)\")\n                else:\n                    status_text.value = \"<p style='color: #666;'>Please upload PDF files to begin</p>\"\n                    process_button.disabled = True\n        \n        def on_process_click(b):\n            \"\"\"Handle process button click\"\"\"\n            with output_widget:\n                clear_output()\n                \n                if not self.uploaded_files:\n                    print(\"❌ No files uploaded\")\n                    return\n                \n                print(\"🚀 Starting PDF processing...\")\n                progress_bar.value = 0\n                \n                results = []\n                total_files = len(self.uploaded_files)\n                \n                for i, (filename, file_path) in enumerate(self.uploaded_files.items()):\n                    progress_bar.value = int((i / total_files) * 90)\n                    \n                    print(f\"\\n📄 Processing: {filename}\")\n                    print(\"─\" * 50)\n                    \n                    try:\n                        # Reset analysis data for each PDF\n                        self.page_findings = {}\n                        self.confidence_scores = {}\n                        self.disambiguation_data = {}\n                        \n                        # Process the PDF\n                        result = self.process_pdf(file_path, \"/kaggle/working\")\n                        \n                        if result['success']:\n                            results.append(result)\n                            print(f\"✅ {filename}: {result['pages_reordered']} pages reordered\")\n                            \n                            # Create download link\n                            output_file = Path(result['output_pdf'])\n                            if output_file.exists():\n                                print(f\"📁 Output saved: {output_file.name}\")\n                        else:\n                            print(f\"❌ {filename}: {result['error']}\")\n                            results.append(result)\n                    \n                    except Exception as e:\n                        print(f\"❌ {filename}: Processing failed - {str(e)}\")\n                        results.append({\n                            'success': False,\n                            'input_path': file_path,\n                            'error': str(e),\n                            'filename': filename\n                        })\n                \n                progress_bar.value = 100\n                \n                # Summary\n                successful = len([r for r in results if r.get('success', False)])\n                failed = len(results) - successful\n                \n                print(f\"\\n🎉 Processing Complete!\")\n                print(f\"✅ Successful: {successful}\")\n                print(f\"❌ Failed: {failed}\")\n                \n                if successful > 0:\n                    print(f\"\\n📁 Output files are saved in /tmp/ directory\")\n                    print(\"You can find the reordered PDFs and analysis reports there.\")\n        \n        # Set up event handlers\n        upload_widget.observe(on_upload_change, names='value')\n        process_button.on_click(on_process_click)\n        \n        # Create UI layout\n        ui = widgets.VBox([\n            widgets.HTML(\"\"\"\n            <div style='text-align: center; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; border-radius: 10px; margin-bottom: 20px;'>\n                <h1 style='margin: 0; font-size: 2.2rem;'>📄 PDF Page Reorderer</h1>\n                <p style='margin: 10px 0 0 0; font-size: 1.1rem; opacity: 0.9;'>Upload PDFs and automatically reorder pages by detected page numbers</p>\n            </div>\n            \"\"\"),\n            upload_widget,\n            status_text,\n            widgets.HBox([process_button], layout=widgets.Layout(justify_content='center')),\n            progress_bar,\n            output_widget\n        ])\n        \n        return ui\n    \n    # [Keep all your existing methods unchanged]\n    def _initialize_ocr(self):\n        try:\n            if self.gpu_optimization and torch.cuda.is_available():\n                torch.cuda.empty_cache()\n                reader = easyocr.Reader(['en'], gpu=True, verbose=False)\n                self.logger.info(f\"GPU initialized. CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")\n            else:\n                reader = easyocr.Reader(['en'], gpu=False, verbose=False)\n                self.logger.info(\"Using CPU for OCR\")\n            return reader\n        except Exception as e:\n            self.logger.error(f\"OCR initialization failed: {e}\")\n            return easyocr.Reader(['en'], gpu=False, verbose=False)\n    \n    # [Include all your existing methods here - they remain unchanged]\n    # analyze_pdf, _analyze_single_page, _standard_ocr, _region_based_ocr,\n    # _multi_resolution_ocr, _extract_numbers_from_ocr, _identify_primary_candidates,\n    # _create_page_mapping, _choose_best_position, create_reordered_pdf, generate_report, process_pdf\n    \n    def analyze_pdf(self, pdf_path):\n        \"\"\"Comprehensive PDF analysis with adaptive page detection\"\"\"\n        if not Path(pdf_path).exists():\n            raise FileNotFoundError(f\"PDF not found: {pdf_path}\")\n        \n        doc = fitz.open(pdf_path)\n        total_pages = len(doc)\n        \n        self.logger.info(f\"Analyzing PDF: {pdf_path}\")\n        self.logger.info(f\"Total pages: {total_pages}\")\n        \n        # Parallel processing for speed\n        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n            futures = []\n            \n            for page_num in range(total_pages):\n                future = executor.submit(self._analyze_single_page, doc, page_num)\n                futures.append((page_num, future))\n            \n            # Collect results\n            for page_num, future in futures:\n                try:\n                    result = future.result(timeout=30)\n                    if result:\n                        self.page_findings[page_num] = result\n                except Exception as e:\n                    self.logger.error(f\"Failed to analyze page {page_num + 1}: {e}\")\n        \n        doc.close()\n        \n        # Clean up GPU memory\n        if self.gpu_optimization:\n            torch.cuda.empty_cache()\n        \n        self.logger.info(f\"Analysis complete. Found page numbers on {len(self.page_findings)} pages\")\n        return self._create_page_mapping()\n    \n    def _analyze_single_page(self, doc, page_num):\n        \"\"\"Analyze single page with multiple OCR approaches\"\"\"\n        page = doc[page_num]\n        \n        # Get page dimensions for region-based analysis\n        rect = page.rect\n        page_width, page_height = rect.width, rect.height\n        \n        all_found_numbers = set()\n        detection_methods = {}\n        \n        try:\n            # Method 1: Standard full-page OCR\n            full_page_numbers = self._standard_ocr(page)\n            all_found_numbers.update(full_page_numbers)\n            if full_page_numbers:\n                detection_methods['full_page'] = full_page_numbers\n            \n            # Method 2: Region-based OCR (header/footer areas)\n            region_numbers = self._region_based_ocr(page, page_width, page_height)\n            all_found_numbers.update(region_numbers)\n            if region_numbers:\n                detection_methods['regions'] = region_numbers\n            \n            # Method 3: Multi-resolution OCR\n            multi_res_numbers = self._multi_resolution_ocr(page)\n            all_found_numbers.update(multi_res_numbers)\n            if multi_res_numbers:\n                detection_methods['multi_res'] = multi_res_numbers\n            \n            # Filter to reasonable page numbers\n            valid_numbers = [n for n in all_found_numbers if 1 <= n <= 200]\n            \n            if valid_numbers:\n                return {\n                    'found_numbers': sorted(valid_numbers),\n                    'detection_methods': detection_methods,\n                    'primary_candidates': self._identify_primary_candidates(valid_numbers, detection_methods)\n                }\n        \n        except Exception as e:\n            self.logger.debug(f\"Error analyzing page {page_num + 1}: {e}\")\n        \n        return None\n    \n    def _standard_ocr(self, page):\n        \"\"\"Standard OCR approach\"\"\"\n        try:\n            pix = page.get_pixmap(matrix=fitz.Matrix(3, 3))  # Optimized resolution\n            img_path = tempfile.mktemp(suffix='.png')\n            pix.save(img_path)\n            \n            # Preprocess image\n            img = Image.open(img_path)\n            enhancer = ImageEnhance.Contrast(img)\n            img = enhancer.enhance(1.3)\n            img = img.convert('L')\n            \n            # OCR\n            results = self.reader.readtext(img_path, detail=True)\n            numbers = self._extract_numbers_from_ocr(results)\n            \n            os.remove(img_path)\n            return numbers\n            \n        except Exception:\n            return []\n    \n    def _region_based_ocr(self, page, page_width, page_height):\n        \"\"\"OCR specific regions where page numbers typically appear\"\"\"\n        numbers = set()\n        \n        # Define key regions\n        regions = [\n            fitz.Rect(0, 0, page_width, page_height * 0.08),  # Top header\n            fitz.Rect(0, page_height * 0.92, page_width, page_height),  # Bottom footer\n            fitz.Rect(page_width * 0.4, page_height * 0.9, page_width * 0.6, page_height),  # Center bottom\n        ]\n        \n        for region in regions:\n            try:\n                pix = page.get_pixmap(matrix=fitz.Matrix(4, 4), clip=region)\n                \n                if pix.width > 20 and pix.height > 10:\n                    img_path = tempfile.mktemp(suffix='.png')\n                    pix.save(img_path)\n                    \n                    # Enhanced preprocessing for small regions\n                    img = Image.open(img_path)\n                    enhancer = ImageEnhance.Contrast(img)\n                    img = enhancer.enhance(2.0)\n                    img = img.convert('L')\n                    \n                    results = self.reader.readtext(img_path, detail=True)\n                    region_numbers = self._extract_numbers_from_ocr(results, min_confidence=0.3)\n                    numbers.update(region_numbers)\n                    \n                    os.remove(img_path)\n                    \n            except Exception:\n                continue\n        \n        return list(numbers)\n    \n    def _multi_resolution_ocr(self, page):\n        \"\"\"OCR at multiple resolutions\"\"\"\n        numbers = set()\n        resolutions = [2, 4, 6]  # Optimized resolution set\n        \n        for zoom in resolutions:\n            try:\n                pix = page.get_pixmap(matrix=fitz.Matrix(zoom, zoom))\n                img_path = tempfile.mktemp(suffix='.png')\n                pix.save(img_path)\n                \n                results = self.reader.readtext(img_path, detail=True)\n                res_numbers = self._extract_numbers_from_ocr(results, min_confidence=0.4)\n                numbers.update(res_numbers)\n                \n                os.remove(img_path)\n                \n            except Exception:\n                continue\n        \n        return list(numbers)\n    \n    def _extract_numbers_from_ocr(self, ocr_results, min_confidence=0.5):\n        \"\"\"Extract page numbers from OCR results using multiple patterns\"\"\"\n        numbers = set()\n        \n        patterns = [\n            (r'^\\s*(\\d+)\\s*$', 1.0),          # Isolated number (high confidence)\n            (r'-\\s*(\\d+)\\s*-', 0.9),          # Dash format\n            (r'page\\s*(\\d+)', 0.8),           # \"Page N\"\n            (r'(\\d+)\\s*$', 0.7),              # Number at line end\n            (r'^\\s*(\\d+)', 0.6),              # Number at line start\n        ]\n        \n        for bbox, text, confidence in ocr_results:\n            if confidence < min_confidence:\n                continue\n            \n            text_clean = text.strip()\n            \n            for pattern, pattern_weight in patterns:\n                matches = re.findall(pattern, text_clean, re.IGNORECASE)\n                for match in matches:\n                    if match.isdigit():\n                        num = int(match)\n                        if 1 <= num <= 200:  # Reasonable page range\n                            numbers.add(num)\n        \n        return list(numbers)\n    \n    def _identify_primary_candidates(self, numbers, methods):\n        \"\"\"Identify the most likely page number candidates\"\"\"\n        # Count detection frequency across methods\n        frequency = Counter()\n        for method_numbers in methods.values():\n            frequency.update(method_numbers)\n        \n        # Return numbers detected by multiple methods or with high confidence\n        primary = []\n        for num, count in frequency.most_common():\n            if count >= 2 or len([m for m in methods.values() if num in m]) >= 2:\n                primary.append(num)\n        \n        return primary[:3]  # Top 3 candidates\n    \n    def _create_page_mapping(self):\n        \"\"\"Create intelligent page number to position mapping\"\"\"\n        self.logger.info(\"Creating page mapping with disambiguation...\")\n        \n        # Collect all page number detections\n        detections = defaultdict(list)\n        for pdf_pos, data in self.page_findings.items():\n            for page_num in data['primary_candidates']:\n                detections[page_num].append(pdf_pos)\n        \n        # Resolve conflicts using heuristics\n        final_mapping = {}\n        used_positions = set()\n        \n        # Sort page numbers for sequential processing\n        for page_num in sorted(detections.keys()):\n            positions = detections[page_num]\n            \n            # Filter out already used positions\n            available_positions = [p for p in positions if p not in used_positions]\n            \n            if available_positions:\n                # Choose best position using heuristics\n                best_pos = self._choose_best_position(page_num, available_positions)\n                final_mapping[page_num] = best_pos\n                used_positions.add(best_pos)\n        \n        self.logger.info(f\"Final mapping created: {len(final_mapping)} pages mapped\")\n        \n        # Log mapping for verification\n        for page_num in sorted(final_mapping.keys()):\n            pdf_pos = final_mapping[page_num]\n            self.logger.info(f\"Page {page_num} -> PDF position {pdf_pos + 1}\")\n        \n        return final_mapping\n    \n    def _choose_best_position(self, page_num, positions):\n        \"\"\"Choose the best PDF position for a page number using heuristics\"\"\"\n        if len(positions) == 1:\n            return positions[0]\n        \n        # Heuristic: prefer positions that have fewer competing page numbers\n        position_scores = {}\n        \n        for pos in positions:\n            score = 0\n            \n            # Prefer positions with fewer total detections\n            total_detections = len(self.page_findings[pos]['found_numbers'])\n            score += 1.0 / (total_detections + 1)\n            \n            # Prefer positions where this page number is a primary candidate\n            if page_num in self.page_findings[pos]['primary_candidates']:\n                score += 1.0\n            \n            # Prefer positions that are reasonable for the page number\n            expected_range_start = max(0, page_num - 3)\n            expected_range_end = min(len(self.page_findings), page_num + 3)\n            if expected_range_start <= pos <= expected_range_end:\n                score += 0.5\n            \n            position_scores[pos] = score\n        \n        return max(positions, key=lambda p: position_scores.get(p, 0))\n    \n    def create_reordered_pdf(self, input_path, output_path, page_mapping):\n        \"\"\"Create reordered PDF based on page mapping\"\"\"\n        if not page_mapping:\n            raise ValueError(\"No page mapping available for reordering\")\n        \n        self.logger.info(f\"Creating reordered PDF: {output_path}\")\n        \n        doc = fitz.open(input_path)\n        reordered_doc = fitz.open()\n        \n        # Sort by page numbers and reorder\n        sorted_pages = sorted(page_mapping.items())\n        \n        for page_num, pdf_position in sorted_pages:\n            reordered_doc.insert_pdf(doc, from_page=pdf_position, to_page=pdf_position)\n            self.logger.debug(f\"Added page {page_num} from PDF position {pdf_position + 1}\")\n        \n        # Save reordered PDF\n        reordered_doc.save(output_path)\n        doc.close()\n        reordered_doc.close()\n        \n        self.logger.info(f\"Reordered PDF saved: {output_path}\")\n        self.logger.info(f\"Pages reordered: {len(sorted_pages)}\")\n        \n        return len(sorted_pages)\n    \n    def generate_report(self, output_path, page_mapping):\n        \"\"\"Generate detailed analysis report\"\"\"\n        report = {\n            'summary': {\n                'total_pdf_pages': len(self.page_findings) if hasattr(self, 'page_findings') else 0,\n                'pages_with_numbers': len([p for p in self.page_findings.values() if p['found_numbers']]),\n                'successful_mappings': len(page_mapping),\n                'page_range': f\"{min(page_mapping.keys())}-{max(page_mapping.keys())}\" if page_mapping else \"None\"\n            },\n            'page_mappings': page_mapping,\n            'detailed_findings': self.page_findings\n        }\n        \n        with open(output_path, 'w') as f:\n            json.dump(report, f, indent=2)\n        \n        self.logger.info(f\"Analysis report saved: {output_path}\")\n    \n    def process_pdf(self, input_path, output_dir=None):\n        \"\"\"Complete PDF processing pipeline\"\"\"\n        input_path = Path(input_path)\n        \n        if not input_path.exists():\n            raise FileNotFoundError(f\"Input PDF not found: {input_path}\")\n        \n        # Setup output paths\n        if output_dir is None:\n            output_dir = \"/kaggle/working/\"\n        else:\n            output_dir = Path(output_dir)\n            output_dir.mkdir(exist_ok=True)\n        \n        base_name = input_path.stem\n        output_pdf = output_dir / f\"{base_name}_reordered.pdf\"\n        report_path = output_dir / f\"{base_name}_analysis_report.json\"\n        \n        try:\n            # Step 1: Analyze PDF\n            self.logger.info(\"Step 1: Analyzing PDF structure...\")\n            page_mapping = self.analyze_pdf(input_path)\n            \n            if not page_mapping:\n                raise ValueError(\"No page numbers could be detected and mapped\")\n            \n            # Step 2: Create reordered PDF\n            self.logger.info(\"Step 2: Creating reordered PDF...\")\n            pages_reordered = self.create_reordered_pdf(input_path, output_pdf, page_mapping)\n            \n            # Step 3: Generate report\n            self.logger.info(\"Step 3: Generating analysis report...\")\n            self.generate_report(report_path, page_mapping)\n            \n            # Summary\n            self.logger.info(\"Processing complete!\")\n            self.logger.info(f\"Input: {input_path}\")\n            self.logger.info(f\"Output: {output_pdf}\")\n            self.logger.info(f\"Report: {report_path}\")\n            self.logger.info(f\"Pages reordered: {pages_reordered}\")\n            \n            return {\n                'success': True,\n                'input_path': str(input_path),\n                'output_pdf': str(output_pdf),\n                'report_path': str(report_path),\n                'pages_reordered': pages_reordered,\n                'page_mapping': page_mapping\n            }\n        \n        except Exception as e:\n            self.logger.error(f\"Processing failed: {e}\")\n            return {\n                'success': False,\n                'error': str(e),\n                'input_path': str(input_path)\n            }\n\n# Easy usage function\ndef create_pdf_reorderer_interface():\n    \"\"\"Create and display the PDF reorderer interface\"\"\"\n    reorderer = AdaptivePDFReorderer(gpu_optimization=True)\n    ui = reorderer.create_upload_widget()\n    \n    if ui:\n        display(ui)\n        return reorderer\n    else:\n        print(\"Please install ipywidgets to use the upload interface:\")\n        print(\"pip install ipywidgets\")\n        return None\n\n# Usage in notebook\nif __name__ == \"__main__\":\n    # For notebook usage\n    print(\"🚀 PDF Page Reorderer - Notebook Version\")\n    print(\"=\" * 50)\n    \n    # Create the interface\n    reorderer = create_pdf_reorderer_interface()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-07T12:09:01.647807Z","iopub.execute_input":"2025-09-07T12:09:01.648138Z","iopub.status.idle":"2025-09-07T12:09:04.190887Z","shell.execute_reply.started":"2025-09-07T12:09:01.648117Z","shell.execute_reply":"2025-09-07T12:09:04.190065Z"}},"outputs":[{"name":"stdout","text":"🚀 PDF Page Reorderer - Notebook Version\n==================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value=\"\\n            <div style='text-align: center; padding: 20px; background: linear-gra…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2248434c80c042b8b56ebe807b3ba84a"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}